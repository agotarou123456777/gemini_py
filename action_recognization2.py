import google.generativeai as genai
import os
import PIL.Image as Image

def load_images_from_dir(dir_path):
  
  images = []
  files = sorted(os.listdir(dir_path))
  
  for file in files:
    file_path = os.path.join(dir_path, file)
    try:
      images.append(Image.open(file_path))
    except Exception as e:
      print(f"Error loading image {file}: {e}")
      images.append(None)
  return images

def getLoopCount(max_image_each_query, num_overlap):
  i = 0
  s = 0
  e = 0 
  while True:
    
    if i == 0:
      s = 0
      e = s + max_image_each_query 
    else:
      s = e + 1 - num_overlap
      e = s + max_image_each_query
    if e > num_images:
      break
    
    i += 1
  
  return i + 1


ENV_KEY_NAME          = "GOOGLE_API_KEY"
MODEL_NAME            = 'gemini-2.0-flash'
MAX_IMAGES            = 80   # æœ€å¤§æŠ•ç¨¿å¯èƒ½æšæ•°
MAX_IMAGES_EACH_QUERY = 20   # å•ã„åˆã‚ã›1å›ã‚ãŸã‚Šã®æœ€å¤§æŠ•ç¨¿ç”»åƒæ•°
IMAGE_OVERLAP_NUM     = 5    # å•ã„åˆã‚ã›é‡è¤‡ç”»åƒæ•°
REFERENCE_IMAGES      = "resource/action_sample"
MAIN_IMAGES           = "export/KVID0169_1fps"

generation_config = {
  "temperature": 0,
  "top_p": 0.95,
  "top_k": 64,
  "max_output_tokens": 8192,
  "response_mime_type": "text/plain",
}



# *** promptè¨­å®š ***

'''å‚è€ƒç”»åƒã«ä»˜ä¸ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ'''
reference_prompt = \
"""\
ã„ã¾ã‹ã‚‰æç¤ºã™ã‚‹ç”»åƒã¯å‚è€ƒç”»åƒã§ã™ã€‚
æ¬¡ã®æŒ‡ç¤ºã«ã—ãŸãŒã£ã¦ã€jsonå½¢å¼ã®ãƒ‡ãƒ¼ã‚¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
ã¾ãŸã€å‚è€ƒç”»åƒã®å›ç­”ä¾‹ã¯ä¸‹è¨˜ã®jsonãƒ‡ãƒ¼ã‚¿ã§ã™ã€‚
{'start' : '15:19:53.372', 'stop' : '15:20:02.404',  'action' : ['ä½œæ¥­ç‰ˆã®å³ä¸Šã‹ã‚‰å‡ºã¦ã„ã‚‹ã‚±ãƒ¼ãƒ–ãƒ«ã‚’ã¾ã¨ã‚ã¾ã™', 'çµæŸãƒãƒ³ãƒ‰ã§çµæŸã—ã¾ã™']},
"""

'''1æšç›®ã®å•ã„åˆã‚ã›ã«ä»˜ä¸ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ'''
first_prompt = \
"""\
æ·»ä»˜ç”»åƒã¯å·¥å ´å†…ã§ã®ä½œæ¥­ã‚’æ’®å½±ã—ãŸæ˜ åƒã‚’ä¸€å®šé–“éš”ã§æŠœãå‡ºã—ãŸã‚‚ã®ã§ã™ã€‚
ç”»åƒå†…ã®å·¦ä¸Šã®æ•°å€¤ã¯æ˜ åƒã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’è¡¨ã—ã¦ã„ã¾ã™ã€‚
ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã¯ã€ã€ŒHH:MM:SS.msã€ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«ãªã£ã¦ã„ã¾ã™ã€‚
ä»¥ä¸‹ã®æŒ‡å®šãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«æ²¿ã£ãŸjsonå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚
jsonå½¢å¼ãƒ‡ãƒ¼ã‚¿ä»¥å¤–ã§ã®å›ç­”ã¯ä¸è¦ã§ã™ã€‚

ã€æŒ‡å®šãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã€‘
{
    'start'  : string, 
    'stop'   : string, 
    'action' : List[string]
}

ãƒ» startã¨stopã¯å„ä½œæ¥­ã®é–‹å§‹æ™‚ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã¨çµ‚äº†æ™‚ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’æ ¼ç´ã—ã¦ãã ã•ã„ã€‚
ãƒ» actionã«ã¯å„ä½œæ¥­ã«ãŠã‘ã‚‹å‹•ä½œèª¬æ˜ã‚’æ ¼ç´ã—ã¦ãã ã•ã„ã€‚
ãƒ» actionã¯ä½œæ¥­ã”ã¨ã«ã²ã¨ã¾ã¨ã‚ã«ã—ã¦ã€ä½œæ¥­å†…ã§è¤‡æ•°ã®å‹•ä½œã‚’è¡Œã£ã¦ã„ã‚‹å ´åˆã¯actionã®ãƒªã‚¹ãƒˆã«å‹•ä½œã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚
ãƒ» å‹•ä½œãŒä¸æ˜ãªå ´åˆã¯actionã¯ã€Œå‹•ä½œä¸æ˜ã€ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚
ãƒ» ç”»åƒå†…ã«äººãŒã„ãªã„å ´åˆã¯actionã¯ã€Œ-ã€ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚
ãƒ» å‹•ä½œã¯è©³ç´°ã«å›ç­”ã—ã€ã§ã£ã¡ã‚ã’ãŸã‚Šå˜˜ã‚’è¨€ã‚ãªã„ã§ãã ã•ã„ã€‚

ã€å‡ºåŠ›ä¾‹ã€‘
[
{'start' : '7:15:12.123', 'stop' : '7:15:15.234',  'action' : ['ä½œæ¥­ãƒ‘ãƒãƒ«ã®å³å´ã®ãƒãƒ³ãƒ‰ãƒ«ã‚’å›ã—ã¾ã™', 'ä½œæ¥­ãƒ‘ãƒãƒ«ã‚’é–‹ãã¾ã™']},
{'start' : '7:15:15.234', 'stop' : '7:15:20.635',  'action' : ['ä½œæ¥­ç‰ˆã®ç·‘è‰²ã®ã‚¹ã‚¤ãƒƒãƒã‚’1ç§’é•·æŠ¼ã—ã—ã¾ã™', 'é»„è‰²ã®ã‚¹ã‚¤ãƒƒãƒã‚’3å›æŠ¼ã—ã¾ã™']},
{'start' : '7:15:20.635', 'stop' : '7:17:01.611',  'action' : '-'},
{'start' : '7:17:01.611', 'stop' : '7:17:31.439',  'action' : ['ç™½æ ã§å›²ã¾ã‚ŒãŸã‚¨ãƒªã‚¢ã«ç§»å‹•ã—ã¾ã™', 'æ®µãƒœãƒ¼ãƒ«ã‚’æŒã¡ä¸Šã’ã¾ã™', 'é»„è‰²ã®ã‚¨ãƒªã‚¢ã«ãƒ€ãƒ³ãƒœãƒ¼ãƒ«ã‚’æŒã£ã¦ç§»å‹•ã—ã¾ã™', 'ãƒ€ãƒ³ãƒœãƒ¼ãƒ«ã‚’é™ã‚ã—ã¾ã™']}
]
"""

# *** ç”»åƒè¨­å®š ***
ref_images = load_images_from_dir(REFERENCE_IMAGES)
main_images = load_images_from_dir(MAIN_IMAGES)
print("num of images in directory : ", len(main_images))
main_images_usage = main_images[:MAX_IMAGES]
num_images = len(main_images_usage)
print("num of images (use) : ", num_images)

num_loop = getLoopCount(max_image_each_query=MAX_IMAGES_EACH_QUERY, num_overlap=IMAGE_OVERLAP_NUM)
print("num loop : ", num_loop)

for i in range(num_loop):
  print(f"\n** Create Model [id:{i}] **")
  
  if i == 0:
    s = 0
    e = s + MAX_IMAGES_EACH_QUERY -1
      
  else:
    s = e + 1 - IMAGE_OVERLAP_NUM
    e = s + MAX_IMAGES_EACH_QUERY - 1
  
  print(f"image index [{s}:{e}]")
    
  messages = []
  genai.configure(api_key=os.environ[ENV_KEY_NAME])
  model = genai.GenerativeModel(MODEL_NAME)
  # reference user query
  prompt = [reference_prompt]
  parts = prompt + ref_images
  user_part = {
    "role" : "user",
    "parts" : parts
  }
  messages.append(user_part)
  
  response = model.generate_content(messages)
  
  # model response
  model_part = {
    "role" : "model",
    "parts" : [response.text]
  }
  messages.append(model_part)
  
  # user main query
  prompt = [first_prompt]
  parts = prompt + main_images[s:e]
  user_part = {
    "role" : "user",
    "parts" : parts
  }
  messages.append(user_part)
  
  response = model.generate_content(messages)
  
  print("ğŸ¤– [model]\n", response.text)